{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amanuel94/Notebooks/blob/main/Embedded_Rebber_Grammars_with_RNNS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2r1QW9B7Hd-",
        "outputId": "5dc5ff87-c164-400b-ec66-5e7741b62284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (5.29.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow --upgrade\n",
        "! pip install keras --upgrade\n",
        "\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njr7a_us908t"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "SEED = 42\n",
        "MAX_LEN = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLiZN4vFzBCW"
      },
      "outputs": [],
      "source": [
        "reber_grammar = {\n",
        "    \"sos\": [(\"B\", \"a\")],\n",
        "    \"a\":[(\"T\", \"b\"), (\"P\", \"c\")],\n",
        "    \"b\": [(\"S\", \"b\"), (\"X\", \"d\")],\n",
        "    \"c\": [(\"T\", \"c\"), (\"V\", \"e\")],\n",
        "    \"d\": [(\"X\", \"c\"), (\"S\", \"f\")],\n",
        "    \"e\": [(\"P\", \"d\"), (\"V\",  \"f\")],\n",
        "    \"f\": [(\"E\", \"eos\")]\n",
        "}\n",
        "\n",
        "embedded_grammar = {\n",
        "    \"sos\":[(\"B\", \"r\")],\n",
        "    \"r\": [(\"T\", \"sost\"), (\"P\", \"sosp\")],\n",
        "    \"sost\": [(\"B\", \"at\")],\n",
        "    \"at\":[(\"T\", \"bt\"), (\"P\", \"ct\")],\n",
        "    \"bt\": [(\"S\", \"bt\"), (\"X\", \"dt\")],\n",
        "    \"ct\": [(\"T\", \"ct\"), (\"V\", \"et\")],\n",
        "    \"dt\": [(\"X\", \"ct\"), (\"S\", \"ft\")],\n",
        "    \"et\": [(\"P\", \"dt\"), (\"V\",  \"ft\")],\n",
        "    \"ft\": [(\"E\", \"eost\")],\n",
        "    \"sosp\": [(\"B\", \"ap\")],\n",
        "    \"ap\":[(\"T\", \"bp\"), (\"P\", \"cp\")],\n",
        "    \"bp\": [(\"S\", \"bp\"), (\"X\", \"dp\")],\n",
        "    \"cp\": [(\"T\", \"ct\"), (\"V\", \"ep\")],\n",
        "    \"dp\": [(\"X\", \"cp\"), (\"S\", \"fp\")],\n",
        "    \"ep\": [(\"P\", \"dp\"), (\"V\",  \"fp\")],\n",
        "    \"fp\": [(\"E\", \"eosp\")],\n",
        "    \"eost\": [(\"T\", \"s\")],\n",
        "    \"eosp\": [(\"P\", \"s\")],\n",
        "    \"s\": [(\"E\", \"eos\")]\n",
        "}\n",
        "\n",
        "# embedded_rebber_grammar = {\n",
        "#     \"esos\": [(\"B\", \"x\")],\n",
        "#     \"x\": [(\"T\", \"sos\"), \"\"]\n",
        "# }\n",
        "\n",
        "nodes = [\"sos\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"eos\"]\n",
        "vocab =  [\"B\", \"T\", \"P\", \"S\", \"X\", \"V\", \"E\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gMghIB67_bP"
      },
      "outputs": [],
      "source": [
        "rnd.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV7V_WUc-IiQ"
      },
      "outputs": [],
      "source": [
        "def generate_string(grammar, member = True, prob = 0.3, by_alphabet = True, decay = 2) :\n",
        "  node = \"sos\"\n",
        "  flag = False\n",
        "  seq = []\n",
        "  while node != \"eos\":\n",
        "    ch, nxt = rnd.choice(grammar[node])\n",
        "    pr = np.random.uniform(0, 1, 1) < prob\n",
        "\n",
        "    # pick a wrong node with probability prob\n",
        "    if pr and not member:\n",
        "      if by_alphabet:\n",
        "        ch = rnd.choice([v for v in vocab if v != ch])\n",
        "      else:\n",
        "        nxt = rnd.choice([v for v in grammar.keys() if v != nxt])\n",
        "      flag = True\n",
        "      prob /= decay\n",
        "\n",
        "    seq.append(ch)\n",
        "    node = nxt\n",
        "\n",
        "  return seq, flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZwGiOmUNBWF"
      },
      "outputs": [],
      "source": [
        "# count = 0\n",
        "# count_prev = 0\n",
        "# for i in range(10000):\n",
        "#   s, f = generate_string(embedded_grammar, False, 0.3, by_alphabet = False, decay = 10)\n",
        "#   if not f:\n",
        "#     count_prev += 1\n",
        "#     s, f = generate_string(embedded_grammar, False, 0.3, by_alphabet = False, decay = 10)\n",
        "#     if not f: count += 1\n",
        "#   # print(\"\".join(s))\n",
        "# print(count, count_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvu8wPSclgmn"
      },
      "outputs": [],
      "source": [
        "words = tf.constant([\"<pad>\"] + vocab)\n",
        "word_ids = tf.range(words.shape[0],  dtype = tf.int64)\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_jBZ_cfVmYY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def prepare(n_instances, n_batch, grammar, decay_dist, max_len = 50):\n",
        "  labels = [0]*(n_instances//2) + [1]*(n_instances//2)\n",
        "  rnd.shuffle(labels)\n",
        "  strings = []\n",
        "  for label in labels:\n",
        "\n",
        "    if label:\n",
        "      s, f = generate_string(grammar)\n",
        "\n",
        "    else:\n",
        "      decay = rnd.choice(decay_dist)\n",
        "      by_alphabet = np.random.uniform(0, 1) > 0.1\n",
        "      s, f = generate_string(grammar, member = False, decay = decay, by_alphabet = by_alphabet)\n",
        "      if not f:\n",
        "        s, f = generate_string(grammar, member = False, decay = decay, by_alphabet = by_alphabet)\n",
        "\n",
        "    # strings.append(s)\n",
        "    # if len(s) < max_len:\n",
        "    #     s = s + [\"<pad>\"]*(max_len - len(s))\n",
        "    strings.append(s)\n",
        "\n",
        "  # strings = list(map(lambda x: index(x), strings))\n",
        "\n",
        "  strings = tf.ragged.constant(strings, ragged_rank = 1)\n",
        "  strings_ds = tf.data.Dataset.from_tensor_slices(strings)\n",
        "\n",
        "  strings_ds = strings_ds.map(lambda x: table.lookup(x))\n",
        "  # strings_ds = strings_ds.bucket_by_sequence_length(\n",
        "  #     element_length_func=lambda elem: tf.shape(elem)[0],\n",
        "  #     bucket_boundaries = [5, 10, 17, 25],\n",
        "  #     bucket_batch_sizes = [n_instances//5]*4 + [n_instances - 4*(n_instances//5)],\n",
        "  #     padding_values = tf.constant(0, dtype = tf.int64)\n",
        "  # )\n",
        "  strings_ds = strings_ds.map(lambda y: tf.one_hot(y, depth = words.shape[0]))\n",
        "\n",
        "  # strings_ds = strings_ds.map(lambda x: x[0])\n",
        "\n",
        "  labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "  ds = tf.data.Dataset.zip(strings_ds, labels_ds)\n",
        "  # ds = ds.map(lambda x, y: (tf.one_hot(x, depth = len(indices)), y))\n",
        "  return ds.padded_batch(n_batch)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pVeqF93Za0Z"
      },
      "outputs": [],
      "source": [
        "decay_dist = [2]*1 + [5]*1 + [10]*7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6iqsXGpclZ",
        "outputId": "047d1d8e-0c15-4998-9454-0610ac885578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 18, 8)\n",
            "(3, 18, 8)\n",
            "(3, 19, 8)\n",
            "(1, 14, 8)\n"
          ]
        }
      ],
      "source": [
        "ds = prepare(10, 3, embedded_grammar, decay_dist, max_len = MAX_LEN,)\n",
        "for a, b in ds:\n",
        "  print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "95k6s434ZO8S"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare(50_000, 32, embedded_grammar, decay_dist, max_len = MAX_LEN)\n",
        "val_ds = prepare(15_000, 32, embedded_grammar, decay_dist, MAX_LEN)\n",
        "test_ds = prepare(10_000, 32, embedded_grammar, decay_dist, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh5B5D81sYNX"
      },
      "outputs": [],
      "source": [
        "# s, f = generate_string(embedded_grammar)\n",
        "# print(s)\n",
        "# print(table.lookup(tf.constant(s + [\"<pad>\"])))\n",
        "# print(tf.one_hot(table.lookup(tf.constant(s + [\"<pad>\"])), depth = 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "u5p3AKLkc3pk",
        "outputId": "7c8e0f8a-56b9-40f0-c0d0-6d1996987f1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru_16 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │          \u001b[38;5;34m33,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_17 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │           \u001b[38;5;34m7,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m630\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,981\u001b[0m (160.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,981</span> (160.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,981\u001b[0m (160.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,981</span> (160.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(shape=[None, words.shape[0]], dtype=tf.int64, ragged=True),\n",
        "    tf.keras.layers.GRU(100, return_sequences=True),\n",
        "    tf.keras.layers.GRU(20),\n",
        "    tf.keras.layers.Dense(30, activation = \"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIHi_5jLxyqs",
        "outputId": "74f36641-a68a-4a6d-ce91-67cb0eb6f7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 45ms/step - accuracy: 0.7068 - loss: 0.5235 - val_accuracy: 0.8333 - val_loss: 0.3930\n",
            "Epoch 2/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.8766 - loss: 0.3143 - val_accuracy: 0.8871 - val_loss: 0.2926\n",
            "Epoch 3/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.9182 - loss: 0.2324 - val_accuracy: 0.9541 - val_loss: 0.1481\n",
            "Epoch 4/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 47ms/step - accuracy: 0.9540 - loss: 0.1474 - val_accuracy: 0.9791 - val_loss: 0.0780\n",
            "Epoch 5/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 47ms/step - accuracy: 0.9758 - loss: 0.0882 - val_accuracy: 0.9831 - val_loss: 0.0611\n",
            "Epoch 6/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 49ms/step - accuracy: 0.9849 - loss: 0.0595 - val_accuracy: 0.9915 - val_loss: 0.0383\n",
            "Epoch 7/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 47ms/step - accuracy: 0.9891 - loss: 0.0446 - val_accuracy: 0.9923 - val_loss: 0.0352\n",
            "Epoch 8/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 45ms/step - accuracy: 0.9931 - loss: 0.0321 - val_accuracy: 0.9935 - val_loss: 0.0318\n",
            "Epoch 9/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 45ms/step - accuracy: 0.9933 - loss: 0.0311 - val_accuracy: 0.9937 - val_loss: 0.0321\n",
            "Epoch 10/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 45ms/step - accuracy: 0.9941 - loss: 0.0282 - val_accuracy: 0.9941 - val_loss: 0.0308\n",
            "Epoch 11/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 45ms/step - accuracy: 0.9950 - loss: 0.0252 - val_accuracy: 0.9943 - val_loss: 0.0303\n",
            "Epoch 12/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.9942 - loss: 0.0282 - val_accuracy: 0.9945 - val_loss: 0.0286\n",
            "Epoch 13/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.9947 - loss: 0.0254 - val_accuracy: 0.9946 - val_loss: 0.0279\n",
            "Epoch 14/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 45ms/step - accuracy: 0.9952 - loss: 0.0237 - val_accuracy: 0.9785 - val_loss: 0.0465\n",
            "Epoch 15/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 45ms/step - accuracy: 0.9933 - loss: 0.0300 - val_accuracy: 0.9947 - val_loss: 0.0272\n",
            "Epoch 16/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.9954 - loss: 0.0232 - val_accuracy: 0.9935 - val_loss: 0.0316\n",
            "Epoch 17/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 47ms/step - accuracy: 0.9952 - loss: 0.0239 - val_accuracy: 0.9947 - val_loss: 0.0274\n",
            "Epoch 18/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.9956 - loss: 0.0223 - val_accuracy: 0.9948 - val_loss: 0.0270\n",
            "Epoch 19/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.9952 - loss: 0.0234 - val_accuracy: 0.9945 - val_loss: 0.0282\n",
            "Epoch 20/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 48ms/step - accuracy: 0.9952 - loss: 0.0232 - val_accuracy: 0.9945 - val_loss: 0.0275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78685e4162f0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss = \"binary_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(train_ds, validation_data = val_ds, epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "zvUAAnAI69LO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84da0562-1bdc-4498-fa1a-cb0d2a75d3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "Estimated probability that these are Reber strings:\n",
            "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 99.44%\n",
            "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 0.89%\n"
          ]
        }
      ],
      "source": [
        "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
        "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
        "X_test = [\n",
        "    tf.one_hot(table.lookup(tf.constant(list(s))), depth = words.shape[0]) for s in test_strings\n",
        "]\n",
        "X_test = tf.data.Dataset.from_tensor_slices(X_test).batch(2)\n",
        "\n",
        "# .map(lambda x: tf.reshape(x, shape = [None, 31, 8]))\n",
        "\n",
        "# X_test\n",
        "\n",
        "y_proba = model.predict(X_test)\n",
        "print()\n",
        "print(\"Estimated probability that these are Reber strings:\")\n",
        "for index, string in enumerate(test_strings):\n",
        "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLknLQwoYKi1YHU0iFzuNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}